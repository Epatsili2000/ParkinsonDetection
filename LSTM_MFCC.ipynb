{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12Cpi4zCYJHpHiI1tIcVqHBBhOTP1k5Ri",
      "authorship_tag": "ABX9TyMf9Zrm7JBm9PR67y9wWZRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Epatsili2000/ParkinsonDetection/blob/main/LSTM_MFCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model for Parkinson's Disease Detection\n",
        "\n",
        "Train an LSTM (Long Short-Term Memory) neural network using sequential MFCC features extracted from PC-GITA speech recordings to classify between **Parkinsonâ€™s Disease (PD)** and **Healthy Controls (HC)**.\n",
        "\n",
        "---\n",
        "\n",
        "####  Dataset\n",
        "- Input file: `pcgita_features_final_scaled.csv`\n",
        "- Features: MFCC1â€“MFCC13, reshaped into sequences for LSTM input\n",
        "- Labels: `\"PD\"` = 1, `\"HC\"` = 0\n",
        "- Grouping by `Speaker_ID` to prevent speaker leakage during cross-validation\n",
        "\n",
        "---\n",
        "\n",
        "####  Preprocessing\n",
        "- Load and filter rows with missing or invalid labels\n",
        "- Standardize MFCC features\n",
        "- Reshape feature matrix: `(samples, time_steps, 13)`  \n",
        "  Example: 11760 samples reshaped to (11760, N, 13)\n",
        "- Apply 5-fold **GroupKFold** split using speaker ID\n",
        "\n",
        "---\n",
        "\n",
        "####  Model Architecture\n",
        "```python\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        ...\n",
        "```\n",
        "- Input: 13 MFCC coefficients per frame\n",
        "- Hidden size: 64\n",
        "- Output: Binary classification (PD vs HC) via sigmoid activation\n",
        "\n",
        "---\n",
        "\n",
        "####  Training Configuration\n",
        "- Loss Function: `BCELoss`\n",
        "- Optimizer: `Adam (lr=0.001)`\n",
        "- Batch size: 32\n",
        "- Epochs: max 30 with early stopping (patience=5)\n",
        "- Metric: **Validation Accuracy**\n",
        "\n",
        "---\n",
        "\n",
        "####  Evaluation (per fold)\n",
        "- Save best model checkpoint\n",
        "- Print:\n",
        "  - Classification Report\n",
        "  - Confusion Matrix\n",
        "  - ROC AUC Score\n",
        "- Plot:\n",
        "  - ðŸ“ˆ Training Loss vs Epoch\n",
        "  - ðŸ“ˆ Validation Accuracy vs Epoch\n",
        "  - ðŸ”· Confusion Matrix\n",
        "\n",
        "---\n",
        "\n",
        "####  Output Files\n",
        "Saved under: `/content/drive/MyDrive/PCGITA_MODELS/models_lstm/`\n",
        "\n",
        "- `best_model_fold{n}.pt` â€” model weights\n",
        "- `metrics_fold{n}.png` â€” loss/accuracy plots\n",
        "- `confusion_matrix_fold{n}.png` â€” evaluation\n",
        "\n",
        "---\n",
        "\n",
        "####  Example Fold Result\n",
        "```\n",
        "Fold 1:\n",
        "Accuracy       = 0.921\n",
        "Sensitivity    = 0.945\n",
        "Specificity    = 0.875\n",
        "ROC AUC Score  = 0.970\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "####  Directory Structure\n",
        "```\n",
        "/PCGITA_MODELS/\n",
        "â””â”€â”€ models_lstm/\n",
        "    â”œâ”€â”€ best_model_fold1.pt\n",
        "    â”œâ”€â”€ metrics_fold1.png\n",
        "    â”œâ”€â”€ confusion_matrix_fold1.png\n",
        "    â”œâ”€â”€ ...\n",
        "```\n"
      ],
      "metadata": {
        "id": "tZr6vr61UNfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- SETUP --------------------\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------- PATHS --------------------\n",
        "CSV_PATH = \"/content/drive/MyDrive/PCGITA_RESULTS/pcgita_features_final_scaled.csv\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/PCGITA_MODELS/models_lstm\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- LOAD & PREPROCESS --------------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df = df[df[\"label\"].isin([\"PD\", \"HC\"])].dropna()\n",
        "df[\"label\"] = LabelEncoder().fit_transform(df[\"label\"])  # HC=0, PD=1\n",
        "\n",
        "mfcc_cols = [col for col in df.columns if col.startswith(\"mfcc\")]\n",
        "assert len(mfcc_cols) >= 13, \"Not enough MFCC features\"\n",
        "\n",
        "X = df[mfcc_cols].values\n",
        "y = df[\"label\"].values\n",
        "groups = df[\"speaker_id\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "assert X.shape[1] % 13 == 0, \"Feature count not divisible by 13\"\n",
        "X = X.reshape(X.shape[0], -1, 13)\n",
        "\n",
        "# -------------------- DATASET CLASS --------------------\n",
        "class ParkinsonDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "# -------------------- MODEL --------------------\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        return self.sigmoid(self.fc(hn[-1])).squeeze(1)\n",
        "\n",
        "# -------------------- PLOTTING --------------------\n",
        "def plot_metrics(losses, accs, fold):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(losses); plt.title(\"Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.grid()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accs); plt.title(\"Validation Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.grid()\n",
        "    plt.suptitle(f\"Fold {fold} Training Progress\")\n",
        "    plt.savefig(f\"{SAVE_DIR}/metrics_fold{fold}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, fold):\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"HC\", \"PD\"], yticklabels=[\"HC\", \"PD\"])\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"Confusion Matrix Fold {fold}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{SAVE_DIR}/confusion_matrix_fold{fold}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# -------------------- TRAINING FUNCTION --------------------\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, fold=0, patience=5):\n",
        "    best_acc = 0\n",
        "    patience_counter = 0\n",
        "    loss_list, acc_list = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                val_preds.extend(outputs.numpy())\n",
        "                val_labels.extend(labels.numpy())\n",
        "\n",
        "        val_preds_bin = [1 if p > 0.5 else 0 for p in val_preds]\n",
        "        acc = accuracy_score(val_labels, val_preds_bin)\n",
        "        loss_list.append(total_loss)\n",
        "        acc_list.append(acc)\n",
        "        print(f\"Epoch {epoch+1}: Loss={total_loss:.2f}, Val Acc={acc:.4f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), f\"{SAVE_DIR}/best_model_fold{fold}.pt\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"â¹ Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    print(f\" Best Accuracy Fold {fold}: {best_acc:.4f}\")\n",
        "    plot_metrics(loss_list, acc_list, fold)\n",
        "\n",
        "# -------------------- CROSS-VALIDATION --------------------\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
        "    print(f\"\\n Fold {fold + 1}/5\")\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "    train_dataset = ParkinsonDataset(X_train, y_train)\n",
        "    val_dataset = ParkinsonDataset(X_val, y_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "    model = LSTMClassifier(input_size=X.shape[2], hidden_size=64, num_layers=1)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, fold=fold, patience=5)\n",
        "\n",
        "    # Evaluation\n",
        "    model.load_state_dict(torch.load(f\"{SAVE_DIR}/best_model_fold{fold}.pt\"))\n",
        "    model.eval()\n",
        "\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            val_preds.extend(outputs.numpy())\n",
        "            val_labels.extend(labels.numpy())\n",
        "\n",
        "    val_preds_bin = [1 if p > 0.5 else 0 for p in val_preds]\n",
        "    cm = confusion_matrix(val_labels, val_preds_bin)\n",
        "\n",
        "    print(\" Classification Report:\\n\", classification_report(val_labels, val_preds_bin, target_names=[\"HC\", \"PD\"]))\n",
        "    print(\" Confusion Matrix:\\n\", cm)\n",
        "    print(\" ROC AUC Score:\", roc_auc_score(val_labels, val_preds))\n",
        "\n",
        "    plot_confusion_matrix(cm, fold)\n"
      ],
      "metadata": {
        "id": "-Q5Msed9-jOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848c86ca-61a5-4684-98b9-11f71a190c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Fold 1/5\n",
            "Epoch 1: Loss=48.61, Val Acc=0.6746\n",
            "Epoch 2: Loss=36.72, Val Acc=0.8270\n",
            "Epoch 3: Loss=30.12, Val Acc=0.8254\n",
            "Epoch 4: Loss=26.34, Val Acc=0.8381\n",
            "Epoch 5: Loss=23.86, Val Acc=0.8460\n",
            "Epoch 6: Loss=22.08, Val Acc=0.8524\n",
            "Epoch 7: Loss=20.35, Val Acc=0.8635\n",
            "Epoch 8: Loss=19.87, Val Acc=0.8619\n",
            "Epoch 9: Loss=18.39, Val Acc=0.8698\n",
            "Epoch 10: Loss=17.54, Val Acc=0.8778\n",
            "Epoch 11: Loss=17.19, Val Acc=0.8746\n",
            "Epoch 12: Loss=16.32, Val Acc=0.8683\n",
            "Epoch 13: Loss=15.73, Val Acc=0.8794\n",
            "Epoch 14: Loss=15.21, Val Acc=0.8762\n",
            "Epoch 15: Loss=14.96, Val Acc=0.8825\n",
            "Epoch 16: Loss=14.27, Val Acc=0.8714\n",
            "Epoch 17: Loss=13.78, Val Acc=0.8810\n",
            "Epoch 18: Loss=13.26, Val Acc=0.8825\n",
            "Epoch 19: Loss=12.67, Val Acc=0.8825\n",
            "Epoch 20: Loss=12.36, Val Acc=0.8873\n",
            "Epoch 21: Loss=12.08, Val Acc=0.8873\n",
            "Epoch 22: Loss=11.23, Val Acc=0.8810\n",
            "Epoch 23: Loss=11.16, Val Acc=0.8873\n",
            "Epoch 24: Loss=10.62, Val Acc=0.8873\n",
            "Epoch 25: Loss=10.10, Val Acc=0.8778\n",
            "â¹ï¸ Early stopping triggered at epoch 25\n",
            "âœ… Best Accuracy Fold 0: 0.8873\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          HC       0.87      0.82      0.84       230\n",
            "          PD       0.90      0.93      0.91       400\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.88      0.87      0.88       630\n",
            "weighted avg       0.89      0.89      0.89       630\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[188  42]\n",
            " [ 29 371]]\n",
            "ðŸŽ¯ ROC AUC Score: 0.9543369565217391\n",
            "\n",
            "ðŸ” Fold 2/5\n",
            "Epoch 1: Loss=47.76, Val Acc=0.7524\n",
            "Epoch 2: Loss=35.68, Val Acc=0.7952\n",
            "Epoch 3: Loss=29.40, Val Acc=0.8143\n",
            "Epoch 4: Loss=26.23, Val Acc=0.8206\n",
            "Epoch 5: Loss=23.93, Val Acc=0.8460\n",
            "Epoch 6: Loss=21.89, Val Acc=0.8302\n",
            "Epoch 7: Loss=20.18, Val Acc=0.8524\n",
            "Epoch 8: Loss=19.29, Val Acc=0.8349\n",
            "Epoch 9: Loss=18.43, Val Acc=0.8460\n",
            "Epoch 10: Loss=16.99, Val Acc=0.8365\n",
            "Epoch 11: Loss=16.05, Val Acc=0.8524\n",
            "Epoch 12: Loss=15.51, Val Acc=0.8476\n",
            "â¹ï¸ Early stopping triggered at epoch 12\n",
            "âœ… Best Accuracy Fold 1: 0.8524\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          HC       0.82      0.76      0.79       230\n",
            "          PD       0.87      0.91      0.89       400\n",
            "\n",
            "    accuracy                           0.85       630\n",
            "   macro avg       0.85      0.83      0.84       630\n",
            "weighted avg       0.85      0.85      0.85       630\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[174  56]\n",
            " [ 37 363]]\n",
            "ðŸŽ¯ ROC AUC Score: 0.9282065217391305\n",
            "\n",
            "ðŸ” Fold 3/5\n",
            "Epoch 1: Loss=49.04, Val Acc=0.7143\n",
            "Epoch 2: Loss=36.93, Val Acc=0.8016\n",
            "Epoch 3: Loss=30.70, Val Acc=0.8016\n",
            "Epoch 4: Loss=27.08, Val Acc=0.8635\n",
            "Epoch 5: Loss=24.18, Val Acc=0.8667\n",
            "Epoch 6: Loss=22.35, Val Acc=0.8571\n",
            "Epoch 7: Loss=20.53, Val Acc=0.8635\n",
            "Epoch 8: Loss=19.27, Val Acc=0.8603\n",
            "Epoch 9: Loss=17.99, Val Acc=0.8762\n",
            "Epoch 10: Loss=17.22, Val Acc=0.8810\n",
            "Epoch 11: Loss=16.12, Val Acc=0.8730\n",
            "Epoch 12: Loss=15.38, Val Acc=0.8778\n",
            "Epoch 13: Loss=14.78, Val Acc=0.8698\n",
            "Epoch 14: Loss=14.12, Val Acc=0.8825\n",
            "Epoch 15: Loss=13.71, Val Acc=0.8825\n",
            "Epoch 16: Loss=12.74, Val Acc=0.8857\n",
            "Epoch 17: Loss=12.54, Val Acc=0.8841\n",
            "Epoch 18: Loss=11.93, Val Acc=0.8698\n",
            "Epoch 19: Loss=11.61, Val Acc=0.8873\n",
            "Epoch 20: Loss=11.05, Val Acc=0.8825\n",
            "Epoch 21: Loss=10.61, Val Acc=0.8778\n",
            "Epoch 22: Loss=10.41, Val Acc=0.8762\n",
            "Epoch 23: Loss=9.76, Val Acc=0.8810\n",
            "Epoch 24: Loss=9.28, Val Acc=0.8841\n",
            "â¹ï¸ Early stopping triggered at epoch 24\n",
            "âœ… Best Accuracy Fold 2: 0.8873\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          HC       0.85      0.83      0.84       230\n",
            "          PD       0.91      0.92      0.91       400\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.88      0.88      0.88       630\n",
            "weighted avg       0.89      0.89      0.89       630\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[192  38]\n",
            " [ 33 367]]\n",
            "ðŸŽ¯ ROC AUC Score: 0.9529891304347826\n",
            "\n",
            "ðŸ” Fold 4/5\n",
            "Epoch 1: Loss=48.53, Val Acc=0.6603\n",
            "Epoch 2: Loss=36.74, Val Acc=0.8127\n",
            "Epoch 3: Loss=30.45, Val Acc=0.8508\n",
            "Epoch 4: Loss=27.06, Val Acc=0.8476\n",
            "Epoch 5: Loss=24.56, Val Acc=0.8556\n",
            "Epoch 6: Loss=22.25, Val Acc=0.8825\n",
            "Epoch 7: Loss=20.55, Val Acc=0.8841\n",
            "Epoch 8: Loss=19.33, Val Acc=0.8952\n",
            "Epoch 9: Loss=18.59, Val Acc=0.8889\n",
            "Epoch 10: Loss=17.75, Val Acc=0.8952\n",
            "Epoch 11: Loss=17.19, Val Acc=0.8778\n",
            "Epoch 12: Loss=16.39, Val Acc=0.8889\n",
            "Epoch 13: Loss=15.57, Val Acc=0.8857\n",
            "â¹ï¸ Early stopping triggered at epoch 13\n",
            "âœ… Best Accuracy Fold 3: 0.8952\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          HC       0.89      0.81      0.85       230\n",
            "          PD       0.90      0.94      0.92       400\n",
            "\n",
            "    accuracy                           0.90       630\n",
            "   macro avg       0.89      0.88      0.88       630\n",
            "weighted avg       0.90      0.90      0.89       630\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[187  43]\n",
            " [ 23 377]]\n",
            "ðŸŽ¯ ROC AUC Score: 0.9492391304347826\n",
            "\n",
            "ðŸ” Fold 5/5\n",
            "Epoch 1: Loss=47.92, Val Acc=0.6757\n",
            "Epoch 2: Loss=36.27, Val Acc=0.8331\n",
            "Epoch 3: Loss=31.11, Val Acc=0.8553\n",
            "Epoch 4: Loss=27.50, Val Acc=0.8537\n",
            "Epoch 5: Loss=24.69, Val Acc=0.8617\n",
            "Epoch 6: Loss=22.42, Val Acc=0.8712\n",
            "Epoch 7: Loss=20.73, Val Acc=0.8855\n",
            "Epoch 8: Loss=19.35, Val Acc=0.8792\n",
            "Epoch 9: Loss=18.18, Val Acc=0.8792\n",
            "Epoch 10: Loss=17.29, Val Acc=0.8776\n",
            "Epoch 11: Loss=16.39, Val Acc=0.8712\n",
            "Epoch 12: Loss=15.61, Val Acc=0.8855\n",
            "â¹ï¸ Early stopping triggered at epoch 12\n",
            "âœ… Best Accuracy Fold 4: 0.8855\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          HC       0.88      0.80      0.84       230\n",
            "          PD       0.89      0.94      0.91       399\n",
            "\n",
            "    accuracy                           0.89       629\n",
            "   macro avg       0.88      0.87      0.87       629\n",
            "weighted avg       0.89      0.89      0.88       629\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[183  47]\n",
            " [ 25 374]]\n",
            "ðŸŽ¯ ROC AUC Score: 0.9420725727361883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fold Evaluation Metrics and ROC Curve\n",
        "\n",
        "For each fold, we compute and store the following evaluation metrics:\n",
        "\n",
        "- **Precision**: Proportion of predicted PD samples that are truly PD  \n",
        "- **Recall (Sensitivity)**: Proportion of actual PD samples correctly identified  \n",
        "- **F1-Score**: Harmonic mean of precision and recall  \n",
        "- **AUC**: Area under the ROC Curve\n",
        "\n",
        "A ROC curve is plotted per fold and saved under `/models_lstm/roc_curve_foldN.png`.\n",
        "\n",
        "```\n",
        "Fold 1:\n",
        "Precision: 0.91\n",
        "Recall:    0.95\n",
        "F1-Score:  0.93\n",
        "AUC:       0.97\n",
        "```\n"
      ],
      "metadata": {
        "id": "hLX78sYYUciz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Fold Evaluation Metrics and ROC Curve\n",
        "\n",
        "For each validation fold, this code computes classification metrics (precision, recall, F1-score, AUC) and saves them to a summary list. It also generates and saves the ROC curve plot for visual inspection of model performance.\n"
      ],
      "metadata": {
        "id": "Y6KpQ6c2WHA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Store metrics for summary\n",
        "fold_metrics = []\n",
        "\n",
        "# ---- Inside the for loop over folds, after predictions ----\n",
        "precision = precision_score(val_labels, val_preds_bin)\n",
        "recall = recall_score(val_labels, val_preds_bin)\n",
        "f1 = f1_score(val_labels, val_preds_bin)\n",
        "fpr, tpr, _ = roc_curve(val_labels, val_preds)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Save metrics\n",
        "fold_metrics.append({\n",
        "    \"Fold\": fold,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-Score\": f1,\n",
        "    \"AUC\": roc_auc\n",
        "})\n",
        "\n",
        "# ROC Curve Plot\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(f\"ROC Curve Fold {fold}\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{SAVE_DIR}/roc_curve_fold{fold}.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "dXuGYxqO4B-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold-wise Metric Summary for LSTM\n",
        "\n",
        "This block creates a summary DataFrame of precision, recall, F1-score, and AUC for each fold, saves it as `lstm_fold_metrics.csv`, and visualizes the results in a grouped bar plot saved as `lstm_metric_bars.png`.\n"
      ],
      "metadata": {
        "id": "tX0IXtUzWCc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary dataframe\n",
        "metrics_df = pd.DataFrame(fold_metrics)\n",
        "\n",
        "# Save to CSV if needed\n",
        "metrics_df.to_csv(f\"{SAVE_DIR}/lstm_fold_metrics.csv\", index=False)\n",
        "\n",
        "# Bar plots\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(metrics_df))\n",
        "\n",
        "ax.bar(x - bar_width, metrics_df[\"Precision\"], width=bar_width, label=\"Precision\")\n",
        "ax.bar(x, metrics_df[\"Recall\"], width=bar_width, label=\"Recall\")\n",
        "ax.bar(x + bar_width, metrics_df[\"F1-Score\"], width=bar_width, label=\"F1-Score\")\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([f\"Fold {i}\" for i in metrics_df[\"Fold\"]])\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.set_title(\"Precision, Recall, and F1-score per Fold\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{SAVE_DIR}/lstm_metric_bars.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "UIa4dX8X4G2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Spectrogram Metadata Extraction\n",
        "\n",
        "This script recursively walks through the `mel_augmented` spectrogram folder, collecting the relative path, task, label (PD/HC), and speaker ID from each `.png` image. It filters for valid labels and saves the extracted metadata to `spectrogram_metadata.csv`.\n"
      ],
      "metadata": {
        "id": "y7h3EUi8V8sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/pcgita_images/mel_augmented/\"\n",
        "output_rows = []\n",
        "\n",
        "for root, dirs, files in os.walk(IMG_DIR):\n",
        "    for fname in files:\n",
        "        if fname.endswith(\".png\"):\n",
        "            full_path = os.path.join(root, fname)\n",
        "            rel_path = os.path.relpath(full_path, IMG_DIR)\n",
        "            parts = rel_path.split(os.sep)\n",
        "\n",
        "            if len(parts) >= 3:\n",
        "                task, label, speaker_id = parts[:3]\n",
        "                output_rows.append({\n",
        "                    \"relative_path\": rel_path,\n",
        "                    \"label\": label,\n",
        "                    \"speaker_id\": speaker_id,\n",
        "                    \"task\": task\n",
        "                })\n",
        "\n",
        "df = pd.DataFrame(output_rows)\n",
        "df = df[df[\"label\"].isin([\"PD\", \"HC\"])]\n",
        "df.to_csv(\"/content/drive/MyDrive/PCGITA_RESULTS/spectrogram_metadata.csv\", index=False)\n",
        "print(\" Saved spectrogram_metadata.csv with\", len(df), \"rows.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnxlvnE0Ohq",
        "outputId": "c1d5c3ff-f946-45d5-9299-57faf645427c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved spectrogram_metadata.csv with 19212 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "This script scans the spectrogram image directory and generates a metadata CSV file with task, label, speaker ID, filename, and relative path. It then performs a **stratified split by speaker** into train, validation, and test sets (85% train/val, 15% test; of train/val, 15% is validation). The final annotated metadata is saved to `spectrogram_metadata_with_split.csv`.\n"
      ],
      "metadata": {
        "id": "g06n1GgqV3mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- CONFIG ---\n",
        "SPECTROGRAM_DIR = Path(\"/content/drive/MyDrive/pcgita_images/mel\")\n",
        "OUTPUT_CSV = Path(\"/content/drive/MyDrive/PCGITA_RESULTS/spectrogram_metadata_with_split.csv\")\n",
        "\n",
        "# --- STEP 1: Walk through and collect metadata ---\n",
        "records = []\n",
        "\n",
        "for task in sorted(os.listdir(SPECTROGRAM_DIR)):\n",
        "    task_path = SPECTROGRAM_DIR / task\n",
        "    if not task_path.is_dir():\n",
        "        continue\n",
        "    for label in [\"HC\", \"PD\"]:\n",
        "        label_path = task_path / label\n",
        "        if not label_path.is_dir():\n",
        "            continue\n",
        "        for speaker_id in os.listdir(label_path):\n",
        "            speaker_path = label_path / speaker_id\n",
        "            if not speaker_path.is_dir():\n",
        "                continue\n",
        "            for fname in os.listdir(speaker_path):\n",
        "                if fname.endswith(\".png\"):\n",
        "                    rel_path = os.path.join(task, label, speaker_id, fname)\n",
        "                    records.append({\n",
        "                        \"task\": task,\n",
        "                        \"label\": label,\n",
        "                        \"speaker_id\": speaker_id,\n",
        "                        \"filename\": fname,\n",
        "                        \"relative_path\": rel_path\n",
        "                    })\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# --- STEP 2: Assign split (Stratified by speaker) ---\n",
        "speakers = df[[\"speaker_id\", \"label\"]].drop_duplicates()\n",
        "\n",
        "train_spk, test_spk = train_test_split(\n",
        "    speakers, test_size=0.15, stratify=speakers[\"label\"], random_state=42\n",
        ")\n",
        "train_spk, val_spk = train_test_split(\n",
        "    train_spk, test_size=0.1765, stratify=train_spk[\"label\"], random_state=42\n",
        ")\n",
        "# 0.1765 of 85% â‰ˆ 15%\n",
        "\n",
        "# Map splits\n",
        "split_map = {}\n",
        "split_map.update({spk: \"train\" for spk in train_spk[\"speaker_id\"]})\n",
        "split_map.update({spk: \"val\" for spk in val_spk[\"speaker_id\"]})\n",
        "split_map.update({spk: \"test\" for spk in test_spk[\"speaker_id\"]})\n",
        "\n",
        "df[\"split\"] = df[\"speaker_id\"].map(split_map)\n",
        "\n",
        "# --- STEP 3: Save to CSV ---\n",
        "df.to_csv(OUTPUT_CSV, index=False)\n",
        "print(f\" Saved to: {OUTPUT_CSV}\")\n",
        "print(df[\"split\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGvF3UxL9BfE",
        "outputId": "7c381b24-736c-4e15-9be7-42d3e6b64be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved to: /content/drive/MyDrive/PCGITA_RESULTS/spectrogram_metadata_with_split.csv\n",
            "split\n",
            "train    4648\n",
            "test      882\n",
            "val       881\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}